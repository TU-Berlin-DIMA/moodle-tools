from __future__ import annotations

import json
import os
import shutil
import sys

os.mkdir("cr_testeval")
shutil.move("__init__.py", "cr_testeval")
shutil.move("cr_testeval.py", "cr_testeval")
shutil.move("ddl_testeval.py", "cr_testeval")

from cr_testeval.cr_testeval import CRTestCase, CRDisplayType
from cr_testeval.ddl_testeval import DDLTestCase

MAX_ROWS = 50
MAX_WIDTH = 500

# Use Twig to get students answer
student_answer = """{{ STUDENT_ANSWER | e('py') }}""".rstrip()

# Parsing the student answer
if not student_answer.endswith(";"):
    student_answer = student_answer + ";"
if "pragma" in student_answer.lower():
    raise ValueError("It is not allowed to use PRAGMA statements.")

# Getting the database file
db_files = [fname for fname in os.listdir() if fname.endswith(".db")]
if len(db_files) == 0:
    db_working = ":memory:"
elif len(db_files) == 1:
    db_working = db_files[0]  # Strip .db extension
else:
    raise Exception("Multiple DB files not implemented yet, sorry!")

test_results = [["Testfall", "Erhalten", "Erwartet", "iscorrect", "ishidden", ""]]

old_stdout = sys.stdout

test_cases = []
# Collecting all test cases
{% for TEST in TESTCASES %}

tc_max = {{ TEST.mark | e('py') }}
tc_max = tc_max if tc_max > 0.005 else 0.0

test_cases.append(
    CRTestCase(
        testcode="""{{ TEST.testcode | e('py') }}""",
        extra="""{{ TEST.extra | e('py') }}""",
        expected_result="""{{ TEST.expected | e('py') }}""",
        testcase_max=tc_max,
        additional_info={{ TEST.stdin | e('py') }},
        hide_rest_if_fail={{ TEST.hiderestiffail | e('py') }},
        display=CRDisplayType.from_str("{{ TEST.display | e('py') }}"),
    ))

{% endfor %}

question_memlimitmb = "{{ QUESTION.memlimitmb | e('py') }}"

abort_tests = False

hide_rest_if_fail = False
awarded_points = 0.0
first_error = ""

for tc in test_cases:
    testcase_max = tc.testcase_max
    if not abort_tests and not hide_rest_if_fail:
        received_result, expected_result, is_correct, errors = DDLTestCase.evaluate_testcase(
            testcase=tc,
            student_answer=student_answer,
            hide_rest_if_fail=hide_rest_if_fail,
            db_working=db_working,
            db_files=db_files,
            max_rows=MAX_ROWS,
            max_width=MAX_WIDTH,
            question_memlimitmb=question_memlimitmb
        )

        testcase_grade = testcase_max if is_correct else 0.0
        awarded_points += testcase_grade

        tc_grade_str = f"{testcase_grade:.3f}" if testcase_max > 0.005 else "â€“â€“â€“"
        tc_max_str = f"{testcase_max:.3f}" if testcase_max > 0.005 else "â€“â€“â€“"

        test_results.append([
            tc.extra,
            " " * (10 - len(tc_grade_str)) + tc_grade_str,
            " " * (10 - len(tc_max_str)) + tc_max_str,
            is_correct,
            hide_rest_if_fail
            or tc.display == CRDisplayType.HIDE
            or (tc.display == CRDisplayType.HIDE_IF_SUCCEED and is_correct)
            or (tc.display == CRDisplayType.HIDE_IF_FAIL and not is_correct),
            ""
        ])

        # append a hidden test case that contains testcode and the results for debugging
        test_results.append([
            tc.extra,
            received_result,
            expected_result,
            is_correct,
            True,
            tc.testcode
        ])

        if errors:
            first_error = [e for e in errors if e.strip()][0] if errors else None
            abort_tests = True

        hide_rest_if_fail = (tc.hide_rest_if_fail and not is_correct) or hide_rest_if_fail

    else:
        tc_max_str = f"{testcase_max:.3f}" if testcase_max > 0.005 else "â€“â€“â€“"

        test_results.append([
            tc.extra,
            " " * 5 + "0.000",
            " " * (10 - len(tc_max_str)) + tc_max_str,
            False,
            not tc.hide_rest_if_fail
        ])

total_points = sum(tc.testcase_max for tc in test_cases)

if first_error:
    error_out = f'<h3>Erste Fehlermeldung</h3><pre style="margin-bottom: 1em"><code>{first_error}</code></pre>'
else:
    error_out = '<h3>Keine Fehlermeldungen gefunden ðŸ™‚</h3>'

output = {
    'fraction': awarded_points / total_points if total_points > 0 else 0,
    'prologuehtml': error_out,
    "epiloguehtml": f"<h3>Gesamtpunktzahl: {awarded_points} / {total_points}</h3>",
    'testresults': test_results,
    "showdifferences": True
}

print(json.dumps(output))
